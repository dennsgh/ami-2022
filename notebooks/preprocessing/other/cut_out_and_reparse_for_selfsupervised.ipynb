{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook can be used to generate additional images for self-supervised learning. It crops similar bounding boxes on the images before and after the ones given with damages to have higher diversity in the dataset for self supervised learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The steps:\n",
    "1. Get a list of the ids\n",
    "2. Get a list of image id's pointing to images ls\n",
    "\n",
    "\n",
    "Make sure your cwd is in /notebooks/preprocessing/. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder is already there\n"
     ]
    }
   ],
   "source": [
    "file = open(Path(\"../original.json\"))\n",
    "original = json.load(file)\n",
    "path = Path(\"../../../data/cropped_additional/\")\n",
    "try:\n",
    "    path.mkdir(parents=True, exist_ok=False)\n",
    "except FileExistsError:\n",
    "    print(\"Folder is already there\")\n",
    "else:\n",
    "    print(\"Folder was created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of image id's 130\n"
     ]
    }
   ],
   "source": [
    "id_list = []\n",
    "same_images = []\n",
    "\n",
    "for entry in original[\"annotations\"]:\n",
    "    if entry['id'] not in id_list:\n",
    "        id_list.append(entry['id'])\n",
    "\n",
    "#populate ph with image id's that has more than 1 image connected to it!\n",
    "ph =[]\n",
    "for entry in original[\"annotations\"]:\n",
    "    for entry2 in original[\"annotations\"]:\n",
    "        if entry2['image_id'] == entry['image_id'] and entry['id'] != entry2['id'] and entry[\"image_id\"] not in ph:\n",
    "            ph.append(entry2['image_id'])\n",
    "        \n",
    "for _ in ph:\n",
    "    tmp = [_]\n",
    "    same_images.append(tmp)\n",
    "    \n",
    "\n",
    "for entry in original[\"annotations\"]:\n",
    "    im_id = entry['image_id']\n",
    "    id = entry['id']\n",
    "    for list in same_images:\n",
    "        if im_id in list and id not in list:\n",
    "            list.append(id)\n",
    "\n",
    "\n",
    "print(r\"Length of image id's {}\".format(len(same_images)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_region(image: np.array, bounding_box) -> np.array:\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "        image: numpy type\n",
    "        bounding_box: Integer\n",
    "\n",
    "    Returns: numpy type\n",
    "\n",
    "    \"\"\"\n",
    "    x_min, y_min, x_range, y_range = bounding_box\n",
    "\n",
    "    _ = np.flipud(image[x_min:x_min + x_range, y_min:y_min + y_range])\n",
    "    _ = np.rot90(_,k=3)\n",
    "\n",
    "    return _\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_root = Path(\"..\", \"..\", \"..\", \"data\", \"Images\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Go through all the images in the same_images list\n",
    "2. Recrop, if the name already exists give a suffix with the image_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of overlap set is 295\n"
     ]
    }
   ],
   "source": [
    "#Unpack to tuple for ease of use\n",
    "\n",
    "overlap = []\n",
    "for list in same_images:\n",
    "    for item in list:\n",
    "        # First element is image_id\n",
    "        if item == list[0]:\n",
    "            continue\n",
    "        ################################\n",
    "        # From here it'll always take id from the list\n",
    "        overlap.append((list[0],item))\n",
    "\n",
    "print(r\"Count of overlap set is {}\".format(len(overlap)))\n",
    "\n",
    "#After cropping this number should match the number of entries in overlap.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "602\n",
      "897\n",
      "Count of disjunct set matches original json entries\n"
     ]
    }
   ],
   "source": [
    "non_overlap = []\n",
    "for entry in original[\"annotations\"]:\n",
    "    if (entry[\"image_id\"],entry[\"id\"]) not in overlap:\n",
    "        non_overlap.append((entry[\"image_id\"], entry[\"id\"]))\n",
    "print(len(non_overlap))\n",
    "print(len(overlap) + len(non_overlap))\n",
    "if(len(overlap) + len(non_overlap) == len(original[\"annotations\"])):\n",
    "    print(\"Count of disjunct set matches original json entries\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "9585\n",
      "897\n"
     ]
    }
   ],
   "source": [
    "# Set up new json\n",
    "# open JSON file\n",
    "categories = original['categories']\n",
    "images = original['images']\n",
    "annotations = original['annotations']\n",
    "\n",
    "# key image ids as key for dict\n",
    "images_keys = [img['id'] for img in images]\n",
    "\n",
    "# get dictionary for filenames\n",
    "images_dict = dict(zip(images_keys, images))\n",
    "# creat a new json file to store the new infomation\n",
    "\n",
    "print(len(categories))\n",
    "print(len(images))\n",
    "print(len(annotations))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "897\n"
     ]
    }
   ],
   "source": [
    "newfile = {\n",
    "    \"categories\": [{\n",
    "        \"id\": 0,\n",
    "        \"name\": \"dent\"\n",
    "    }, {\n",
    "        \"id\": 1,\n",
    "        \"name\": \"other\"\n",
    "    }, {\n",
    "        \"id\": 2,\n",
    "        \"name\": \"rim\"\n",
    "    }, {\n",
    "        \"id\": 3,\n",
    "        \"name\": \"scratch\"\n",
    "    }, {\n",
    "        \"id\": 4,\n",
    "        \"name\": \"deformation\"\n",
    "    }],\n",
    "    \"images\": [],\n",
    "    \"annotations\": []\n",
    "}\n",
    "\n",
    "# Deal with non overlapping ones first\n",
    "\n",
    "# take prelabeled labels and put them by image_id(because they are non overlap and unique)\n",
    "#from 600-896 (1 to 897 in total, index from 0)\n",
    "pre_den = json.load(open(Path(\"..\",\"..\", \"etc\", \"prelabeled_den.json\")))\n",
    "#from 300-599\n",
    "pre_mag = json.load(open(Path(\"..\", \"..\", \"etc\", \"prelabeled_mag.json\")))\n",
    "#from 0-299\n",
    "#pre_thu = json.load(open(Path(\"..\", \"etc\", \"prelabeled_thu.json\")))\n",
    "stitched = {\"annotations\": []}\n",
    "\n",
    "for i in range(300):\n",
    "    stitched[\"annotations\"].append(pre_mag[\"annotations\"][i])\n",
    "\n",
    "for i in range(300,600):\n",
    "    stitched[\"annotations\"].append(pre_mag[\"annotations\"][i])\n",
    "\n",
    "for i in range(600,897):\n",
    "    stitched[\"annotations\"].append(pre_den[\"annotations\"][i])\n",
    "\n",
    "print(len(stitched[\"annotations\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "897 entries matched, valid\n",
      "725 entries were relabeled.\n"
     ]
    }
   ],
   "source": [
    "count =0\n",
    "relabeled_count=0\n",
    "for newentry in stitched[\"annotations\"]:\n",
    "    for entry in original[\"annotations\"]:\n",
    "        if(entry[\"id\"] == newentry[\"id\"]):\n",
    "            count+=1\n",
    "            if(entry[\"category_id\"] != newentry[\"category_id\"]):\n",
    "                relabeled_count+=1\n",
    "if count == len(original[\"annotations\"]):\n",
    "    print(r\"{} entries matched, valid\".format(count))\n",
    "\n",
    "print(r\"{} entries were relabeled.\".format(relabeled_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No problems found.\n"
     ]
    }
   ],
   "source": [
    "problem_set = []\n",
    "\n",
    "def get_labeled_category(id,img_id):\n",
    "    for entry in stitched[\"annotations\"]:\n",
    "        if entry[\"id\"] == id and entry[\"image_id\"] == img_id:\n",
    "            return entry[\"category_id\"]\n",
    "    print(\"Not found!\")\n",
    "    problem_set.append((id, img_id))\n",
    "\n",
    "\n",
    "images_entries = original[\"images\"]\n",
    "cropped_path = Path(\"..\", \"..\", \"..\", \"data\", \"cropped_additional\")\n",
    "if (len(problem_set) == 0):\n",
    "    print(\"No problems found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not_found: 0\n"
     ]
    }
   ],
   "source": [
    "#only need the annotations entries since the rest are obsolete\n",
    "\n",
    "not_found = 0\n",
    "\n",
    "for entry in original[\"annotations\"]:\n",
    "    if((entry[\"image_id\"],entry[\"id\"]) in non_overlap ):\n",
    "        # Only access images in the list\n",
    "        id = entry[\"id\"]\n",
    "        image_id = entry['image_id']\n",
    "        bounding_box = entry['bbox']\n",
    "        for i in [2,3]:\n",
    "            if bounding_box[i] < 150:\n",
    "                if bounding_box[i-2]-75 >0:\n",
    "                    bounding_box[i - 2] = bounding_box[i - 2] - 75\n",
    "                    bounding_box[i] = 150\n",
    "                else:\n",
    "                    bounding_box[i] = 150\n",
    "        filename = images_dict[image_id]['file_name']\n",
    "        #get filename of file before given image\n",
    "        [filename_begin, _] = filename.split('.')\n",
    "        for i in range(1,5):\n",
    "            filename_split = filename_begin.split('_')\n",
    "            filename_split[-1] = str(int(filename_split[-1]) + i)\n",
    "            filename_begin = '_'.join(filename_split)\n",
    "            if Path(image_root,'.'.join([filename_begin, 'webp'])).is_file():\n",
    "                filename = '.'.join([filename_begin, 'webp'])\n",
    "                break\n",
    "            elif Path(image_root,'.'.join([filename_begin, 'jpeg'])).is_file():\n",
    "                filename = '.'.join([filename_begin, 'jpeg'])\n",
    "                break\n",
    "            elif i==5:\n",
    "                print(filename)\n",
    "                filename = None\n",
    "        if filename:\n",
    "            fp = Path(image_root, filename)\n",
    "            #ONLY get the category_id from prelabeled ones for NON overlap, overlap ones need relabeling, and shall be marked with category_id 1\n",
    "            category_id = get_labeled_category(id,image_id)\n",
    "            img = Image.open(fp)\n",
    "            numpy_image = np.transpose(np.array(img), (1, 0, 2))\n",
    "            cropped_image = crop_region(numpy_image, bounding_box)\n",
    "            cropped_image = Image.fromarray(cropped_image)\n",
    "            save_path = Path(cropped_path,str(id)+\"+1.png\")\n",
    "            cropped_image.save(save_path)\n",
    "            save_path = save_path.relative_to(\"../../../data/\").as_posix()\n",
    "            fp = fp.relative_to(\"../../../data\").as_posix()\n",
    "            # Fill out the data\n",
    "            # image id refers to the source, non cropped image\n",
    "            new_annotation = {\n",
    "                \"id\": id,\n",
    "                \"category_id\": category_id,\n",
    "                'image_id': image_id,\n",
    "                'filepath': save_path,\n",
    "                'source': fp,\n",
    "                \"bbox\": bounding_box\n",
    "            }\n",
    "\n",
    "            newfile['annotations'].append(new_annotation)\n",
    "        else:\n",
    "            not_found += 1\n",
    "\n",
    "print(\"not_found: \" + str(not_found))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not_found: 0\n"
     ]
    }
   ],
   "source": [
    "#only need the annotations entries since the rest are obsolete\n",
    "\n",
    "not_found = 0\n",
    "\n",
    "for entry in original[\"annotations\"]:\n",
    "    if((entry[\"image_id\"],entry[\"id\"]) in non_overlap ):\n",
    "        # Only access images in the list\n",
    "        id = entry[\"id\"]\n",
    "        image_id = entry['image_id']\n",
    "        bounding_box = entry['bbox']\n",
    "        for i in [2, 3]:\n",
    "            if bounding_box[i] < 150:\n",
    "                if bounding_box[i - 2] - 75 > 0:\n",
    "                    bounding_box[i - 2] = bounding_box[i - 2] - 75\n",
    "                    bounding_box[i] = 150\n",
    "                else:\n",
    "                    bounding_box[i] = 150\n",
    "        filename = images_dict[image_id]['file_name']\n",
    "        #print(filename)\n",
    "        #get filename of file before given image\n",
    "        [filename_begin, _] = filename.split('.')\n",
    "        for i in range(1,5):\n",
    "            filename_split = filename_begin.split('_')\n",
    "            filename_split[-1] = str(int(filename_split[-1]) - i)\n",
    "            filename_begin = '_'.join(filename_split)\n",
    "            if Path(image_root,'.'.join([filename_begin, 'webp'])).is_file():\n",
    "                filename = '.'.join([filename_begin, 'webp'])\n",
    "                break\n",
    "            elif Path(image_root,'.'.join([filename_begin, 'jpeg'])).is_file():\n",
    "                filename = '.'.join([filename_begin, 'jpeg'])\n",
    "                break\n",
    "            elif i==5:\n",
    "                print(filename)\n",
    "                filename = None\n",
    "        if filename:\n",
    "            fp = Path(image_root, filename)\n",
    "            #ONLY get the category_id from prelabeled ones for NON overlap, overlap ones need relabeling, and shall be marked with category_id 1\n",
    "            category_id = get_labeled_category(id,image_id)\n",
    "            img = Image.open(fp)\n",
    "            numpy_image = np.transpose(np.array(img), (1, 0, 2))\n",
    "            cropped_image = crop_region(numpy_image, bounding_box)\n",
    "            cropped_image = Image.fromarray(cropped_image)\n",
    "            save_path = Path(cropped_path,str(id)+\"-1.png\")\n",
    "            cropped_image.save(save_path)\n",
    "            save_path = save_path.relative_to(\"../../../data/\").as_posix()\n",
    "            fp = fp.relative_to(\"../../../data\").as_posix()\n",
    "            # Fill out the data\n",
    "            # image id refers to the source, non cropped image\n",
    "            new_annotation = {\n",
    "                \"id\": id,\n",
    "                \"category_id\": category_id,\n",
    "                'image_id': image_id,\n",
    "                'filepath': save_path,\n",
    "                'source': fp,\n",
    "                \"bbox\": bounding_box\n",
    "            }\n",
    "\n",
    "            newfile['annotations'].append(new_annotation)\n",
    "        else:\n",
    "            not_found += 1\n",
    "\n",
    "print(\"not_found: \" + str(not_found))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not_found: 0\n"
     ]
    }
   ],
   "source": [
    "#only need the annotations entries since the rest are obsolete\n",
    "\n",
    "not_found = 0\n",
    "\n",
    "for entry in original[\"annotations\"]:\n",
    "    if ((entry[\"image_id\"], entry[\"id\"]) in overlap):\n",
    "        # Only access images in the list\n",
    "        id = entry[\"id\"]\n",
    "        image_id = entry['image_id']\n",
    "        bounding_box = entry['bbox']\n",
    "        for i in [2, 3]:\n",
    "            if bounding_box[i] < 150:\n",
    "                if bounding_box[i - 2] - 75 > 0:\n",
    "                    bounding_box[i - 2] = bounding_box[i - 2] - 75\n",
    "                    bounding_box[i] = 150\n",
    "                else:\n",
    "                    bounding_box[i] = 150\n",
    "        filename = images_dict[image_id]['file_name']\n",
    "        #print(filename)\n",
    "        #get filename of file before given image\n",
    "        [filename_begin, _ ] = filename.split('.')\n",
    "        for i in range(1, 5):\n",
    "            filename_split = filename_begin.split('_')\n",
    "            filename_split[-1] = str(int(filename_split[-1]) + i)\n",
    "            filename_begin = '_'.join(filename_split)\n",
    "            if Path(image_root, '.'.join([filename_begin, 'webp'])).is_file():\n",
    "                filename = '.'.join([filename_begin, 'webp'])\n",
    "                break\n",
    "            elif Path(image_root, '.'.join([filename_begin, 'jpeg'])).is_file():\n",
    "                filename = '.'.join([filename_begin, 'jpeg'])\n",
    "                break\n",
    "            elif i == 5:\n",
    "                print(filename)\n",
    "                filename = None\n",
    "        if filename:\n",
    "            fp = Path(image_root, filename)\n",
    "            img = Image.open(fp)\n",
    "            numpy_image = np.transpose(np.array(img), (1, 0, 2))\n",
    "            cropped_image = crop_region(numpy_image, bounding_box)\n",
    "            cropped_image = Image.fromarray(cropped_image)\n",
    "            save_path = Path(cropped_path, str(id) + \"+1.png\")\n",
    "            cropped_image.save(save_path)\n",
    "            save_path = save_path.relative_to(\"../../../data\").as_posix()\n",
    "            fp = fp.relative_to(\"../../../data\").as_posix()\n",
    "            # Fill out the data\n",
    "            # image id refers to the source, non cropped image\n",
    "            new_annotation = {\n",
    "                \"id\": id,\n",
    "                \"category_id\": 1,\n",
    "                'image_id': image_id,\n",
    "                'filepath': save_path,\n",
    "                'source': fp,\n",
    "                \"bbox\": bounding_box\n",
    "            }\n",
    "\n",
    "            newfile['annotations'].append(new_annotation)\n",
    "        else:\n",
    "            not_found += 1\n",
    "print(\"not_found: \" + str(not_found))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not_found: 0\n"
     ]
    }
   ],
   "source": [
    "#only need the annotations entries since the rest are obsolete\n",
    "\n",
    "not_found = 0\n",
    "\n",
    "for entry in original[\"annotations\"]:\n",
    "    if ((entry[\"image_id\"], entry[\"id\"]) in overlap):\n",
    "        # Only access images in the list\n",
    "        id = entry[\"id\"]\n",
    "        image_id = entry['image_id']\n",
    "        bounding_box = entry['bbox']\n",
    "        for i in [2, 3]:\n",
    "            if bounding_box[i] < 150:\n",
    "                if bounding_box[i - 2] - 75 > 0:\n",
    "                    bounding_box[i - 2] = bounding_box[i - 2] - 75\n",
    "                    bounding_box[i] = 150\n",
    "                else:\n",
    "                    bounding_box[i] = 150\n",
    "        filename = images_dict[image_id]['file_name']\n",
    "        #print(filename)\n",
    "        #get filename of file before given image\n",
    "        [filename_begin, _ ] = filename.split('.')\n",
    "        for i in range(1, 5):\n",
    "            filename_split = filename_begin.split('_')\n",
    "            filename_split[-1] = str(int(filename_split[-1]) - i)\n",
    "            filename_begin = '_'.join(filename_split)\n",
    "            if Path(image_root, '.'.join([filename_begin, 'webp'])).is_file():\n",
    "                filename = '.'.join([filename_begin, 'webp'])\n",
    "                break\n",
    "            elif Path(image_root, '.'.join([filename_begin, 'jpeg'])).is_file():\n",
    "                filename = '.'.join([filename_begin, 'jpeg'])\n",
    "                break\n",
    "            elif i == 5:\n",
    "                print(filename)\n",
    "                filename = None\n",
    "        if filename:\n",
    "            fp = Path(image_root, filename)\n",
    "            img = Image.open(fp)\n",
    "            numpy_image = np.transpose(np.array(img), (1, 0, 2))\n",
    "            cropped_image = crop_region(numpy_image, bounding_box)\n",
    "            cropped_image = Image.fromarray(cropped_image)\n",
    "            save_path = Path(cropped_path, str(id) + \"-1.png\")\n",
    "            cropped_image.save(save_path)\n",
    "            save_path = save_path.relative_to(\"../../../data\").as_posix()\n",
    "            fp = fp.relative_to(\"../../../data\").as_posix()\n",
    "            # Fill out the data\n",
    "            # image id refers to the source, non cropped image\n",
    "            new_annotation = {\n",
    "                \"id\": id,\n",
    "                \"category_id\": 1,\n",
    "                'image_id': image_id,\n",
    "                'filepath': save_path,\n",
    "                'source': fp,\n",
    "                \"bbox\": bounding_box\n",
    "            }\n",
    "\n",
    "            newfile['annotations'].append(new_annotation)\n",
    "        else:\n",
    "            not_found += 1\n",
    "print(\"not_found: \" + str(not_found))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "for entry in original[\"images\"]:\n",
    "    fp = Path(image_root,entry['file_name'])\n",
    "    fp = fp.relative_to(\"../../../data\").as_posix()\n",
    "    new_images = {\n",
    "        \"id\": entry['id'],\n",
    "        \"filepath\": fp,\n",
    "        \"width\": entry['width'],\n",
    "        \"height\": entry['height']\n",
    "    }\n",
    "    newfile['images'].append(new_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting dictionaries to json\n",
    "#json_test = json.dumps(newfile)\n",
    "#with open('restructured.json', 'w') as json_file:\n",
    "#    json_file.write(json_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('tensorflow-vscode')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d9211170195b23e32e5df2c41afaa48bfa42c9866ca7a1b4a91e6a8922db1531"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
