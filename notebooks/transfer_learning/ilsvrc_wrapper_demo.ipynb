{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db6f7a3d",
   "metadata": {},
   "source": [
    "# Transfer Learning with EfficientNetV2S\n",
    " \n",
    "##### Get the new sorted dataset [here](https://tumde-my.sharepoint.com/:f:/g/personal/gohdennis_tum_de/EmooVZ4vE95Iic-HIP9-P10BzX7oIOBmRhK8Q9tYzfJWRQ?e=maOqo5) [08_Aug_2022]\n",
    "\n",
    "Annotations are stored under notebooks/preprocesing/restructured_w_original_labels.json and do not to be moved (also in the .zip file)\n",
    "\n",
    "Extract the zip from the link (sort.zip) under data/.\n",
    "\n",
    "\n",
    "<hr style=\"height:2px;border-width:0;color:black;background-color:black\">\n",
    "\n",
    "This notebook will show the EfficientNetWrapper in action.\n",
    "\n",
    "\n",
    "\n",
    "### [EfficientNet](https://paperswithcode.com/method/efficientnet)\n",
    "\n",
    "The EfficientNet introduces a model scaling methods and applies it to ResNet and MobileNets. Additionally, the researchers apply neural architecture search to design a new baseline network (EfficientNet), to then scale it up to create the EfficientNet family. The EfficientNetB7 achieves state-of-the-art 84.3% top-1 accuracy on ImageNet, while being 8.4x smaller and 6.1x faster on inference than the best existing ConvNet.\n",
    "\n",
    "In the second iteration of the network architecture, the researches improve on model performance and size by using Fusion-MBConv layer instead of the classical MBCOnv layer introduced with MobileNet\n",
    "\n",
    "### [Keras Availability](https://keras.io/api/applications/efficientnet_v2/)\n",
    "\n",
    "The entire network and the pretrained weights for the LSVRC[ImageNet Large Scale Visual Recognition Challenge] are provided by keras. The ImageNet dataset is a large scale collection of labled images with:\n",
    "- 14 million images\n",
    "- 1 million images with bounding boxes\n",
    "- 20.000 categories using WordNet schema (eg. family then species then race)\n",
    "\n",
    "Lets begin by preparing and inspecting our data. When we feel confident in our ability to handle what is provided, we can begin to fit the SOTA network. Since the training is computationally demanding, make sure tensorflow is running on your GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a887bbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import zipfile\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pdb\n",
    "import shutil\n",
    "from models.ilsvrc import EfficientNetV2S\n",
    "from preprocessing.rand_augmenter import RandAugmenterWrapper\n",
    "from keras.callbacks import  EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02f92948",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-25 19:37:43.603436: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-25 19:37:43.603680: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-25 19:37:43.603857: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-25 19:37:43.604111: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-25 19:37:43.604299: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-25 19:37:43.604424: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /device:GPU:0 with 5057 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Ti, pci bus id: 0000:08:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.get_logger().setLevel('INFO')\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a845ec0c",
   "metadata": {},
   "source": [
    "## I. Load Data\n",
    "To begin our showcase, we load the data from the directory, after setting it up as specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "868699c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 897 files belonging to 4 classes.\n",
      "Using 628 files for training.\n",
      "Found 897 files belonging to 4 classes.\n",
      "Using 269 files for validation.\n"
     ]
    }
   ],
   "source": [
    "image_path = Path(os.getenv(\"DATA\"), \"sort\")\n",
    "\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(directory=image_path,\n",
    "                                                       validation_split=0.3,\n",
    "                                                       subset='training',\n",
    "                                                       seed=0,\n",
    "                                                       image_size=(224, 224))\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(directory=image_path,\n",
    "                                                     validation_split=0.3,\n",
    "                                                     subset='validation',\n",
    "                                                     seed=0,\n",
    "                                                     image_size=(224, 224))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8196e9",
   "metadata": {},
   "source": [
    "## II. Model Configuration\n",
    "Next we can configure our model. The configuration targets the top networks only. Most parameters are self explanatory. \n",
    "- layer_size: either as integer or tuple.\n",
    "- depth: Creates sequential network with layer_size if the later is interger. Else ignored.\n",
    "- pooling_type: either max or average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d90db464",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = {\"layer_size\": (128, 32), \"dropout\": 0.1, \"pooling_type\": \"max\"}\n",
    "\n",
    "model = EfficientNetV2S(**model_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce52b421",
   "metadata": {},
   "source": [
    "## III. Data Augmentation\n",
    "\n",
    "Before running our model, we need prepend an augmentation layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d7ea2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentation_ops = [\n",
    "    'Invert',\n",
    "    'Rotate',\n",
    "    'Posterize',\n",
    "    'Solarize',\n",
    "    'SolarizeAdd',\n",
    "    'Color',\n",
    "    'Contrast',\n",
    "    'Brightness',\n",
    "    'TranslateX',\n",
    "    'TranslateY',\n",
    "]\n",
    "\n",
    "augmentation_layer = RandAugmenterWrapper(num_layers=2,\n",
    "                                            magnitude=7,\n",
    "                                            op_list=augmentation_ops)\n",
    "model.prepend_layer(augmentation_layer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1985c713",
   "metadata": {},
   "source": [
    "## IV. Training the Model\n",
    "We can now fit the model to the data. Remember, the model holds every method from tf.keras.Model and can be called in such manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc43a228",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer= \"adam\", loss= \"sparse_categorical_crossentropy\", metrics= ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ff16b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-25 19:37:53.922688: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8500\n",
      "2022-08-25 19:37:54.565580: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 3/20 [===>..........................] - ETA: 1s - loss: 5.9425 - accuracy: 0.3021"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-25 19:37:55.244322: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 13s 252ms/step - loss: 4.2272 - accuracy: 0.6178 - val_loss: 2.3937 - val_accuracy: 0.7732\n",
      "Epoch 2/40\n",
      "20/20 [==============================] - 3s 118ms/step - loss: 1.6441 - accuracy: 0.7500 - val_loss: 0.9826 - val_accuracy: 0.8141\n",
      "Epoch 3/40\n",
      "20/20 [==============================] - 2s 112ms/step - loss: 0.9115 - accuracy: 0.8041 - val_loss: 0.9931 - val_accuracy: 0.7993\n",
      "Epoch 4/40\n",
      "20/20 [==============================] - 2s 117ms/step - loss: 0.5262 - accuracy: 0.8742 - val_loss: 0.7870 - val_accuracy: 0.8216\n",
      "Epoch 5/40\n",
      "20/20 [==============================] - 2s 117ms/step - loss: 0.5516 - accuracy: 0.8551 - val_loss: 0.7393 - val_accuracy: 0.8216\n",
      "Epoch 6/40\n",
      "20/20 [==============================] - 2s 112ms/step - loss: 0.6233 - accuracy: 0.8567 - val_loss: 1.3115 - val_accuracy: 0.7323\n",
      "Epoch 7/40\n",
      "20/20 [==============================] - 2s 112ms/step - loss: 0.3806 - accuracy: 0.8901 - val_loss: 0.8540 - val_accuracy: 0.8141\n",
      "Epoch 8/40\n",
      "20/20 [==============================] - 2s 112ms/step - loss: 0.2596 - accuracy: 0.9156 - val_loss: 0.7533 - val_accuracy: 0.8141\n",
      "Epoch 9/40\n",
      "20/20 [==============================] - 2s 115ms/step - loss: 0.2803 - accuracy: 0.9347 - val_loss: 0.7263 - val_accuracy: 0.8364\n",
      "Epoch 10/40\n",
      "20/20 [==============================] - 2s 112ms/step - loss: 0.2425 - accuracy: 0.9299 - val_loss: 1.5534 - val_accuracy: 0.7138\n",
      "Epoch 11/40\n",
      "20/20 [==============================] - 2s 115ms/step - loss: 0.3826 - accuracy: 0.8981 - val_loss: 0.6513 - val_accuracy: 0.8327\n",
      "Epoch 12/40\n",
      "20/20 [==============================] - 2s 113ms/step - loss: 0.3028 - accuracy: 0.9315 - val_loss: 0.7515 - val_accuracy: 0.8401\n",
      "Epoch 13/40\n",
      "20/20 [==============================] - 2s 112ms/step - loss: 0.2546 - accuracy: 0.9315 - val_loss: 0.7838 - val_accuracy: 0.8364\n",
      "Epoch 14/40\n",
      "20/20 [==============================] - 2s 112ms/step - loss: 0.1540 - accuracy: 0.9538 - val_loss: 0.9104 - val_accuracy: 0.7993\n",
      "Epoch 15/40\n",
      "20/20 [==============================] - 2s 113ms/step - loss: 0.2308 - accuracy: 0.9204 - val_loss: 1.0303 - val_accuracy: 0.7918\n",
      "Epoch 16/40\n",
      "20/20 [==============================] - 2s 113ms/step - loss: 0.3728 - accuracy: 0.8933 - val_loss: 1.7028 - val_accuracy: 0.7509\n",
      "Epoch 17/40\n",
      "20/20 [==============================] - 2s 112ms/step - loss: 0.3411 - accuracy: 0.9268 - val_loss: 0.9282 - val_accuracy: 0.8178\n",
      "Epoch 18/40\n",
      "20/20 [==============================] - 2s 113ms/step - loss: 0.1851 - accuracy: 0.9459 - val_loss: 1.0035 - val_accuracy: 0.8216\n",
      "Epoch 19/40\n",
      "20/20 [==============================] - 2s 113ms/step - loss: 0.1306 - accuracy: 0.9538 - val_loss: 0.9776 - val_accuracy: 0.8067\n",
      "Epoch 20/40\n",
      "20/20 [==============================] - 2s 113ms/step - loss: 0.2429 - accuracy: 0.9475 - val_loss: 1.1598 - val_accuracy: 0.7955\n",
      "Epoch 21/40\n",
      "20/20 [==============================] - 3s 119ms/step - loss: 0.1329 - accuracy: 0.9506 - val_loss: 0.9027 - val_accuracy: 0.8290\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fea9419fb80>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gc import callbacks\n",
    "\n",
    "\n",
    "es_callback = EarlyStopping(\n",
    "    patience=10,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=40,\n",
    "    callbacks=[es_callback]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b215147",
   "metadata": {},
   "source": [
    "We can proceed by unfreezing blocks. But first lets insepect the total number of blocks available by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3706f3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.num_blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7dc67c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "20/20 [==============================] - 9s 196ms/step - loss: 0.1770 - accuracy: 0.9490 - val_loss: 0.6616 - val_accuracy: 0.8364\n",
      "Epoch 2/40\n",
      "20/20 [==============================] - 2s 114ms/step - loss: 0.1152 - accuracy: 0.9650 - val_loss: 0.6575 - val_accuracy: 0.8364\n",
      "Epoch 3/40\n",
      "20/20 [==============================] - 2s 113ms/step - loss: 0.1493 - accuracy: 0.9490 - val_loss: 0.6640 - val_accuracy: 0.8439\n",
      "Epoch 4/40\n",
      "20/20 [==============================] - 2s 112ms/step - loss: 0.1292 - accuracy: 0.9570 - val_loss: 0.6636 - val_accuracy: 0.8327\n",
      "Epoch 5/40\n",
      "20/20 [==============================] - 2s 112ms/step - loss: 0.1011 - accuracy: 0.9682 - val_loss: 0.6674 - val_accuracy: 0.8327\n",
      "Epoch 6/40\n",
      "20/20 [==============================] - 2s 113ms/step - loss: 0.0947 - accuracy: 0.9666 - val_loss: 0.6691 - val_accuracy: 0.8327\n",
      "Epoch 7/40\n",
      "20/20 [==============================] - 2s 113ms/step - loss: 0.0815 - accuracy: 0.9777 - val_loss: 0.6694 - val_accuracy: 0.8364\n",
      "Epoch 8/40\n",
      "20/20 [==============================] - 2s 112ms/step - loss: 0.1216 - accuracy: 0.9586 - val_loss: 0.6683 - val_accuracy: 0.8327\n",
      "Epoch 9/40\n",
      "20/20 [==============================] - 2s 113ms/step - loss: 0.0904 - accuracy: 0.9713 - val_loss: 0.6683 - val_accuracy: 0.8327\n",
      "Epoch 10/40\n",
      "20/20 [==============================] - 2s 112ms/step - loss: 0.0794 - accuracy: 0.9697 - val_loss: 0.6779 - val_accuracy: 0.8290\n",
      "Epoch 11/40\n",
      "20/20 [==============================] - 2s 113ms/step - loss: 0.1030 - accuracy: 0.9682 - val_loss: 0.6765 - val_accuracy: 0.8290\n",
      "Epoch 12/40\n",
      "20/20 [==============================] - 2s 112ms/step - loss: 0.1118 - accuracy: 0.9713 - val_loss: 0.6746 - val_accuracy: 0.8327\n",
      "Epoch 13/40\n",
      "20/20 [==============================] - 2s 113ms/step - loss: 0.0744 - accuracy: 0.9745 - val_loss: 0.6757 - val_accuracy: 0.8327\n",
      "Epoch 14/40\n",
      "20/20 [==============================] - 2s 113ms/step - loss: 0.0734 - accuracy: 0.9761 - val_loss: 0.6770 - val_accuracy: 0.8327\n",
      "Epoch 15/40\n",
      "20/20 [==============================] - 2s 113ms/step - loss: 0.1074 - accuracy: 0.9634 - val_loss: 0.6751 - val_accuracy: 0.8327\n",
      "Epoch 16/40\n",
      "20/20 [==============================] - 2s 113ms/step - loss: 0.1160 - accuracy: 0.9666 - val_loss: 0.6805 - val_accuracy: 0.8290\n",
      "Epoch 17/40\n",
      "20/20 [==============================] - 2s 113ms/step - loss: 0.0924 - accuracy: 0.9634 - val_loss: 0.6836 - val_accuracy: 0.8439\n",
      "Epoch 18/40\n",
      "20/20 [==============================] - 2s 112ms/step - loss: 0.1011 - accuracy: 0.9618 - val_loss: 0.6764 - val_accuracy: 0.8327\n",
      "Epoch 19/40\n",
      "20/20 [==============================] - 2s 112ms/step - loss: 0.0840 - accuracy: 0.9777 - val_loss: 0.6800 - val_accuracy: 0.8290\n",
      "Epoch 20/40\n",
      "20/20 [==============================] - 2s 114ms/step - loss: 0.0876 - accuracy: 0.9713 - val_loss: 0.6876 - val_accuracy: 0.8290\n",
      "Epoch 21/40\n",
      "20/20 [==============================] - 2s 114ms/step - loss: 0.0859 - accuracy: 0.9761 - val_loss: 0.6819 - val_accuracy: 0.8364\n",
      "Epoch 22/40\n",
      "20/20 [==============================] - 2s 113ms/step - loss: 0.0788 - accuracy: 0.9729 - val_loss: 0.6804 - val_accuracy: 0.8327\n",
      "Epoch 23/40\n",
      "20/20 [==============================] - 2s 113ms/step - loss: 0.0704 - accuracy: 0.9729 - val_loss: 0.6825 - val_accuracy: 0.8364\n",
      "Epoch 24/40\n",
      "20/20 [==============================] - 2s 112ms/step - loss: 0.0854 - accuracy: 0.9761 - val_loss: 0.6866 - val_accuracy: 0.8290\n",
      "Epoch 25/40\n",
      "20/20 [==============================] - 2s 112ms/step - loss: 0.0782 - accuracy: 0.9713 - val_loss: 0.6961 - val_accuracy: 0.8253\n",
      "Epoch 26/40\n",
      "20/20 [==============================] - 2s 111ms/step - loss: 0.0635 - accuracy: 0.9777 - val_loss: 0.6851 - val_accuracy: 0.8290\n",
      "Epoch 27/40\n",
      "20/20 [==============================] - 2s 113ms/step - loss: 0.0809 - accuracy: 0.9666 - val_loss: 0.6824 - val_accuracy: 0.8327\n",
      "Epoch 28/40\n",
      "20/20 [==============================] - 2s 113ms/step - loss: 0.0637 - accuracy: 0.9793 - val_loss: 0.6828 - val_accuracy: 0.8327\n",
      "Epoch 29/40\n",
      "20/20 [==============================] - 2s 112ms/step - loss: 0.0923 - accuracy: 0.9729 - val_loss: 0.6841 - val_accuracy: 0.8401\n",
      "Epoch 30/40\n",
      "20/20 [==============================] - 2s 114ms/step - loss: 0.0575 - accuracy: 0.9873 - val_loss: 0.6875 - val_accuracy: 0.8290\n",
      "Epoch 31/40\n",
      "20/20 [==============================] - 2s 113ms/step - loss: 0.0727 - accuracy: 0.9729 - val_loss: 0.6881 - val_accuracy: 0.8327\n",
      "Epoch 32/40\n",
      "20/20 [==============================] - 2s 114ms/step - loss: 0.0587 - accuracy: 0.9793 - val_loss: 0.6911 - val_accuracy: 0.8290\n",
      "Epoch 33/40\n",
      "20/20 [==============================] - 2s 114ms/step - loss: 0.0831 - accuracy: 0.9713 - val_loss: 0.6941 - val_accuracy: 0.8290\n",
      "Epoch 34/40\n",
      "20/20 [==============================] - 2s 113ms/step - loss: 0.0785 - accuracy: 0.9713 - val_loss: 0.6899 - val_accuracy: 0.8327\n",
      "Epoch 35/40\n",
      "20/20 [==============================] - 2s 113ms/step - loss: 0.0678 - accuracy: 0.9777 - val_loss: 0.6975 - val_accuracy: 0.8290\n",
      "Epoch 36/40\n",
      "20/20 [==============================] - 2s 112ms/step - loss: 0.0781 - accuracy: 0.9713 - val_loss: 0.6934 - val_accuracy: 0.8327\n",
      "Epoch 37/40\n",
      "20/20 [==============================] - 2s 112ms/step - loss: 0.0645 - accuracy: 0.9809 - val_loss: 0.6954 - val_accuracy: 0.8290\n",
      "Epoch 38/40\n",
      "20/20 [==============================] - 2s 113ms/step - loss: 0.0719 - accuracy: 0.9761 - val_loss: 0.6960 - val_accuracy: 0.8290\n",
      "Epoch 39/40\n",
      "20/20 [==============================] - 2s 112ms/step - loss: 0.0685 - accuracy: 0.9825 - val_loss: 0.6990 - val_accuracy: 0.8253\n",
      "Epoch 40/40\n",
      "20/20 [==============================] - 2s 112ms/step - loss: 0.0585 - accuracy: 0.9809 - val_loss: 0.6971 - val_accuracy: 0.8327\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe9a1fe49a0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.00001),\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=['accuracy'])\n",
    "model.trainable_blocks = 10\n",
    "model.fit(train_ds, validation_data=val_ds, epochs=40, callbacks=[es_callback])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0928f4d7",
   "metadata": {},
   "source": [
    "## V. Score the Model\n",
    "\n",
    "The model can be evaluated as usually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "45d6b8f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 67ms/step - loss: 0.6971 - accuracy: 0.8327\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6971398591995239, 0.832713782787323]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(val_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0e241f",
   "metadata": {},
   "source": [
    "## VI. Nice to Have's\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c77aae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "model.plot_base_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
