{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ILSVRC Pipeline Demo \n",
    " \n",
    "##### Get the new sorted dataset [here](https://tumde-my.sharepoint.com/:f:/g/personal/gohdennis_tum_de/EmooVZ4vE95Iic-HIP9-P10BzX7oIOBmRhK8Q9tYzfJWRQ?e=maOqo5) [08_Aug_2022]\n",
    "\n",
    "Annotations are stored under notebooks/preprocesing/restructured_w_original_labels.json (also in the .zip file)\n",
    "\n",
    "Extract the zip under data/.\n",
    "\n",
    "\n",
    "<hr style=\"height:2px;border-width:0;color:black;background-color:black\">\n",
    "\n",
    "This notebook will show case the functioning of the EfficientNet pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-23 17:10:11.536639: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from models.ilsvrc import EfficientNetV2S\n",
    "from pipelines.ilsvrc import EfficientNetPipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Load Data\n",
    "To begin our showcase, we load the data from the directory, after setting it up as specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 897 files belonging to 4 classes.\n",
      "Using 628 files for training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-23 17:10:20.787471: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-23 17:10:20.926351: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-23 17:10:20.926737: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-23 17:10:20.931878: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-08-23 17:10:20.943939: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-23 17:10:20.944401: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-23 17:10:20.944701: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-23 17:10:23.787863: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-23 17:10:23.788234: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-23 17:10:23.788513: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-23 17:10:23.788741: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4658 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti with Max-Q Design, pci bus id: 0000:02:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 897 files belonging to 4 classes.\n",
      "Using 269 files for validation.\n"
     ]
    }
   ],
   "source": [
    "image_path = Path(os.getenv(\"DATA\"), \"sort\")\n",
    "\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(directory=image_path,\n",
    "                                                       validation_split=0.3,\n",
    "                                                       subset='training',\n",
    "                                                       seed=0,\n",
    "                                                       image_size=(224, 224))\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(directory=image_path,\n",
    "                                                     validation_split=0.3,\n",
    "                                                     subset='validation',\n",
    "                                                     seed=0,\n",
    "                                                     image_size=(224, 224))\n",
    "\n",
    "# get current working directory\n",
    "\n",
    "json_file = Path(\"resources\", \"restructured_w_original_labels.json\")\n",
    "json_target = Path(os.getenv(\"DATA\"), json_file.name)\n",
    "shutil.copy(str(json_file), str(json_target))\n",
    "with json_target.open() as f:\n",
    "    data = json.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Configuring the Pipeline\n",
    "\n",
    "Before we run the pipeline, we need to configure the model and the pipeline hyperparameters. The model parameters are mostly self explanatory, pooling_type refers to the pooling layer between the final base model layer and the first top network layer.\n",
    "\n",
    "The pipeline config feature the following notable parameters:\n",
    "- epochs: max number of epochs. Early stopping might cut the training of.\n",
    "- model_name: directory name, where the run is to be executed\n",
    "- store_model: stores the best model iteration as a checkpoint\n",
    "- patience: after how many epochs without improvement in val_loss the operation should stop\n",
    "- callbacks: if needed additional callbacks can be passed as a list\n",
    "- custom_objects: dictionary pointing to custom objectes for the compiler configuration\n",
    "- save_weights_only: stores entire model if False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = {\"layer_size\": (128, 32), \"dropout\": 0.1, \"pooling_type\": \"max\"}\n",
    "\n",
    "pipeline_config = {\n",
    "    \"batch_size\": 32,\n",
    "    \"epochs\": 40,\n",
    "    \"model_name\": \"trial\",\n",
    "    \"store_model\": True,\n",
    "    \"patience\": 10,\n",
    "    \"compiler_config\": {\n",
    "        \"optimizer\": \"adam\",\n",
    "        \"loss\": \"sparse_categorical_crossentropy\",\n",
    "        \"metrics\": ['accuracy']\n",
    "    }\n",
    "}\n",
    "\n",
    "model = EfficientNetV2S(**model_config)\n",
    "pipeline = EfficientNetPipeline(model, **pipeline_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Fitting the Model\n",
    "Next, we can continue by fitting the model to the data. This will create the model directory under Group04/models/trial, containing checkpoints and history. The fit method returns a json with history. The execution is fully resilient to crashes and as long as the models directory is intact, it will always remember its previous run. Try interupting and restarting the notebook to see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model.\n",
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-23 17:10:59.673404: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 21s 409ms/step - loss: 6.3784 - accuracy: 0.5462 - val_loss: 6.2784 - val_accuracy: 0.5353 - lr: 0.0010\n",
      "Epoch 2/40\n",
      "20/20 [==============================] - 5s 214ms/step - loss: 2.2149 - accuracy: 0.7229 - val_loss: 1.4127 - val_accuracy: 0.7398 - lr: 0.0010\n",
      "Epoch 3/40\n",
      "20/20 [==============================] - 5s 230ms/step - loss: 1.0925 - accuracy: 0.8121 - val_loss: 1.2755 - val_accuracy: 0.7584 - lr: 0.0010\n",
      "Epoch 4/40\n",
      "20/20 [==============================] - 5s 218ms/step - loss: 1.2446 - accuracy: 0.8121 - val_loss: 1.2452 - val_accuracy: 0.7695 - lr: 0.0010\n",
      "Epoch 5/40\n",
      "20/20 [==============================] - 5s 217ms/step - loss: 0.9067 - accuracy: 0.8153 - val_loss: 0.8454 - val_accuracy: 0.8104 - lr: 0.0010\n",
      "Epoch 6/40\n",
      "20/20 [==============================] - 4s 197ms/step - loss: 0.5348 - accuracy: 0.8901 - val_loss: 1.3420 - val_accuracy: 0.7658 - lr: 0.0010\n",
      "Epoch 7/40\n",
      "20/20 [==============================] - 4s 195ms/step - loss: 0.7763 - accuracy: 0.8487 - val_loss: 1.0594 - val_accuracy: 0.7993 - lr: 0.0010\n",
      "Epoch 8/40\n",
      "20/20 [==============================] - 4s 196ms/step - loss: 0.4209 - accuracy: 0.9140 - val_loss: 0.9617 - val_accuracy: 0.7770 - lr: 0.0010\n",
      "Epoch 9/40\n",
      "20/20 [==============================] - 4s 203ms/step - loss: 0.2272 - accuracy: 0.9315 - val_loss: 0.9064 - val_accuracy: 0.8067 - lr: 0.0010\n",
      "Epoch 10/40\n",
      "20/20 [==============================] - 5s 219ms/step - loss: 0.3381 - accuracy: 0.9156 - val_loss: 0.8014 - val_accuracy: 0.8401 - lr: 0.0010\n",
      "Epoch 11/40\n",
      "20/20 [==============================] - 5s 220ms/step - loss: 0.2050 - accuracy: 0.9490 - val_loss: 0.7638 - val_accuracy: 0.8216 - lr: 0.0010\n",
      "Epoch 12/40\n",
      "20/20 [==============================] - 5s 245ms/step - loss: 0.4451 - accuracy: 0.9045 - val_loss: 0.8719 - val_accuracy: 0.8253 - lr: 0.0010\n",
      "Epoch 13/40\n",
      "20/20 [==============================] - 5s 250ms/step - loss: 0.3593 - accuracy: 0.9172 - val_loss: 0.8039 - val_accuracy: 0.8401 - lr: 0.0010\n",
      "Epoch 14/40\n",
      "20/20 [==============================] - 6s 307ms/step - loss: 0.2223 - accuracy: 0.9363 - val_loss: 0.8521 - val_accuracy: 0.8253 - lr: 0.0010\n",
      "Epoch 15/40\n",
      "20/20 [==============================] - 5s 217ms/step - loss: 0.1558 - accuracy: 0.9490 - val_loss: 0.8109 - val_accuracy: 0.8439 - lr: 0.0010\n",
      "Epoch 16/40\n",
      "20/20 [==============================] - 5s 224ms/step - loss: 0.2393 - accuracy: 0.9363 - val_loss: 1.9681 - val_accuracy: 0.7472 - lr: 0.0010\n",
      "Epoch 17/40\n",
      "20/20 [==============================] - 5s 220ms/step - loss: 0.5380 - accuracy: 0.8774 - val_loss: 1.3380 - val_accuracy: 0.7807 - lr: 0.0010\n",
      "Epoch 18/40\n",
      "20/20 [==============================] - 5s 223ms/step - loss: 0.3507 - accuracy: 0.9092 - val_loss: 0.8662 - val_accuracy: 0.8327 - lr: 0.0010\n",
      "Epoch 19/40\n",
      "20/20 [==============================] - 5s 230ms/step - loss: 0.2286 - accuracy: 0.9379 - val_loss: 0.8004 - val_accuracy: 0.8290 - lr: 0.0010\n",
      "Epoch 20/40\n",
      "20/20 [==============================] - 4s 194ms/step - loss: 0.1411 - accuracy: 0.9554 - val_loss: 0.8865 - val_accuracy: 0.8327 - lr: 0.0010\n",
      "Epoch 21/40\n",
      "20/20 [==============================] - 4s 202ms/step - loss: 0.2272 - accuracy: 0.9363 - val_loss: 0.8363 - val_accuracy: 0.8476 - lr: 0.0010\n",
      "Training complete.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe68a2dd3d0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = pipeline.fit(train_ds, val_ds)\n",
    "history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV. Operate the Model\n",
    "After having fitted the model, you can continue by scoring and predicting different data. Scores are saved to the history.json."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 117ms/step - loss: 0.7638 - accuracy: 0.8216\n",
      "9/9 [==============================] - 4s 124ms/step\n",
      "9/9 [==============================] - 1s 121ms/step\n"
     ]
    }
   ],
   "source": [
    "score = pipeline.score(val_ds)\n",
    "pred = pipeline.predict(val_ds)\n",
    "pred_class = pipeline.predict_class(val_ds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
